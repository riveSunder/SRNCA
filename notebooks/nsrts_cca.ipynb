{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up notebook for cloud\n",
    "\n",
    "# on colab, you'll probably need to restart runtime after running the commands below\n",
    "\n",
    "#! mkdir nsrts/weights\n",
    "#! gdown 1np2iNoc7WVL0p7XxXFmCslrkGda3UIdr -O nsrts/weights/\n",
    "\n",
    "#! git clone https://github.com/riveSunder/NeuralSymbolicRegressionThatScales.git nsrts\n",
    "#! pip install nsrts/src/\n",
    "#! pip install pytorch-lightning\n",
    "#! pip install torch==1.11\n",
    "#! pip install libtorch\n",
    "\n",
    "#! git clone https://github.com/riveSunder/yuca.git\n",
    "#! pip install -e ./yuca/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc91986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory fro NeuralSymbolicRegressionThatScales\n",
    "# e.g. on colab `nsrts_dir = \"nsrts\"\n",
    "nsrts_dir = \"../nsrts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c59798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 256\n",
    "\n",
    "import matplotlib.animation\n",
    "import IPython\n",
    "\n",
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify\n",
    "\n",
    "import sympy as sp\n",
    "import json\n",
    "\n",
    "from yuca.lenia import Lenia\n",
    "from yuca.zoo.librarian import Librarian\n",
    "from yuca.utils import seed_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lenia_fn(neighborhood_conv, growth_fn, dt):\n",
    "    \"\"\"\n",
    "    given the convolution and growth functions, and a step size dt\n",
    "    return a function that implements a continuous CA under Lenia framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def update_ca_fn(grid):\n",
    "        \n",
    "        nbhd = neighborhood_conv(grid)\n",
    "        growth = growth_fn(nbhd)\n",
    "        \n",
    "        #grid = torch.tensor(np.clip(grid.clone().detach() + dt * growth, 0.0, 1.0)).clone().detach().to(grid.dtype).clone().detach()\n",
    "        grid = torch.clamp(grid + dt*growth, 0, 1.0).double().to(grid.dtype)\n",
    "        \n",
    "        return grid\n",
    "    \n",
    "    return update_ca_fn\n",
    "\n",
    "# functions facilitating IPython animation\n",
    "# initializing the plot\n",
    "def plot_grid(grid):\n",
    "    \n",
    "    global subplot_0 \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,6), facecolor=\"white\")\n",
    "    \n",
    "    subplot_0 = ax.imshow(grid.numpy().squeeze(), cmap=\"magma\", interpolation=\"nearest\")\n",
    "    \n",
    "    ax.set_xticklabels(\"\")\n",
    "    ax.set_yticklabels(\"\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# updating the figure during animation\n",
    "def update_fig(ii):\n",
    "    \n",
    "    global subplot_0\n",
    "    global grid\n",
    "    global update_ca_fn\n",
    "    \n",
    "    grid = update_ca_fn(grid)\n",
    "    \n",
    "    subplot_0.set_array(grid.numpy().squeeze())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user configurable options\n",
    "\n",
    "use_toy_data = False\n",
    "\n",
    "# whether to get input x/y dataset from CA simulation\n",
    "use_ca_dynamics = True\n",
    "\n",
    "# Gaussian and the Lenia Orbium params\n",
    "mu = 0.15\n",
    "sigma = 0.015\n",
    "gaussian = lambda x: np.exp(-((x -mu) / sigma)**2)\n",
    "\n",
    "\n",
    "# seed pseudorandom number generators\n",
    "seed_all(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_toy_data:\n",
    "    pass\n",
    "else:\n",
    "    \n",
    "    ca = Lenia()\n",
    "    ca.restore_config(\"orbium.npy\")\n",
    "    ca.no_grad()\n",
    "\n",
    "    x = np.arange(-0.1,1.5, 0.001)\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw={\"width_ratios\": [0.2, 0.8]}, figsize=(12,3))\n",
    "    ax[0].imshow(ca.neighborhood_kernels.squeeze(), cmap=\"magma\")\n",
    "    ax[0].set_title(\"neighborhood kernel\")\n",
    "    ax[1].plot(x, ca.genesis_fns[0](x))\n",
    "    ax[1].set_title(\"growth function\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #grid[:,:, -64:, :64] = torch.rand(64,64)\n",
    "    if use_ca_dynamics:\n",
    "        \n",
    "        grid = torch.zeros(1,1,128,128)\n",
    "        my_steps = 32\n",
    "        num_patterns = 5\n",
    "        dim_rand = 54\n",
    "        lib = Librarian()\n",
    "\n",
    "        grid[:,:, :dim_rand, :] = torch.rand(dim_rand, grid.shape[-1])\n",
    "\n",
    "        pattern, _ = lib.load(\"orbium_orbium000\")\n",
    "\n",
    "        for ii in range(num_patterns):\n",
    "            grid[:,:,25*ii:25*ii+pattern.shape[-2], 25*ii:25*ii + pattern.shape[-1]] = torch.tensor(pattern)\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(grid.squeeze(), cmap=\"magma\")\n",
    "\n",
    "        for step in range(my_steps):\n",
    "            #neighborhood = ca.neighborhood_conv(grid)\n",
    "            #old_grid = 1.0 * grid\n",
    "            grid = ca(grid)\n",
    "\n",
    "        #grid[:,:, :dim_rand, -dim_rand:] = torch.rand(dim_rand,dim_rand)\n",
    "\n",
    "        neighborhood = ca.neighborhood_conv(grid)\n",
    "        old_grid = 1.0 * grid\n",
    "        grid = ca(grid)\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(neighborhood.squeeze(), cmap=\"magma\")\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(old_grid.squeeze(), cmap=\"magma\")\n",
    "        plt.show()\n",
    "\n",
    "       \n",
    "    else:\n",
    "        # use random uniform inputs to ca\n",
    "        grid = torch.rand(1, 1, 128, 128)\n",
    "        grid_ramp = torch.tensor(np.arange(0,1,1/grid.shape[-1])).reshape(1,1,1,grid.shape[-1])\n",
    "        \n",
    "        grid = (grid * grid_ramp).to(grid.dtype)\n",
    "\n",
    "        neighborhood = ca.neighborhood_conv(grid)\n",
    "        old_grid = 1.0 * grid\n",
    "        grid = ca(grid)\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(neighborhood.squeeze(), cmap=\"magma\")\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(old_grid.squeeze(), cmap=\"magma\")\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    x0 = old_grid.numpy().ravel().reshape(-1,1)\n",
    "    x1 = neighborhood.numpy().ravel().reshape(-1,1)\n",
    "\n",
    "    #data_x = np.append(x0, x1, axis=1)\n",
    "    data_x = x1 \n",
    "    data_y = ca.genesis_fns[0](data_x) #grid.ravel().reshape(-1,1)\n",
    "\n",
    "\n",
    "    print(x0.shape, x1.shape, data_x.shape, data_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load equation configuration and architecture configuration\n",
    "import omegaconf\n",
    "\n",
    "json_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"eq_setting.json\")\n",
    "with open(json_filepath, 'r') as json_file:\n",
    "    eq_setting = json.load(json_file)\n",
    "     \n",
    "cfg_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"config.yaml\")\n",
    "cfg = omegaconf.OmegaConf.load(cfg_filepath)\n",
    "    \n",
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust this parameter up for greater accuracy and longer runtime\n",
    "cfg.inference.beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38041f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )\n",
    "\n",
    "weights_path = os.path.join(nsrts_dir, \"weights\", \"100M.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f572a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = partial(model.fitfunc, cfg_params=params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape: \", data_x.shape)\n",
    "print(\"y shape: \", data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(16384, 8000)\n",
    "\n",
    "output = fitfunc(data_x[idx], data_y[idx].squeeze()) \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23789908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"best_bfgs_preds\"])\n",
    "\n",
    "sr_fn = lambda x: sp.lambdify(\"x_1\", output[\"best_bfgs_preds\"])(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"best_bfgs_preds\"])\n",
    "\n",
    "sr_fn = lambda x: sp.lambdify(\"x_1\", output[\"best_bfgs_preds\"])(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a41d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.mean(), data_x.std(), data_x.min(), data_x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the SR growth function\n",
    "my_x = data_x[:1000]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(my_x, gaussian(my_x), \"o\", color=\"r\")\n",
    "plt.plot(my_x, sr_fn(my_x), \"x\", color=\"b\", alpha=0.1)\n",
    "\n",
    "plt.plot(my_x, np.clip(sr_fn(my_x),0,1),\".\",  color=\"b\", alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7358f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the dynamics. Do patterns behave as expected? \n",
    "num_frames = 100\n",
    "grid = torch.zeros(1,1,96,96)\n",
    "\n",
    "lib =  Librarian()\n",
    "ca = Lenia()\n",
    "ca.restore_config(\"orbium.npy\")\n",
    "ca.no_grad()\n",
    "\n",
    "pattern, _ = lib.load(\"orbium_orbium000\")\n",
    "grid[:,:,50:72,50:72] = torch.tensor(pattern)\n",
    "\n",
    "print(ca.neighborhood_conv(grid).max())\n",
    "update_ca_fn  = get_lenia_fn(ca.neighborhood_conv, sr_fn, ca.dt)\n",
    "\n",
    "fig, ax = plot_grid(grid)\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "IPython.display.HTML(matplotlib.animation.FuncAnimation(fig, update_fig, frames=num_frames, interval=100).to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a47c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6df93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
